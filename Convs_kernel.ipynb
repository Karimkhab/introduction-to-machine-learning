{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNiMryBSs9b7YBd8cMXXj1Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Karimkhab/introduction-to-machine-learning/blob/main/Convs_kernel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from abc import ABC, abstractmethod"
      ],
      "metadata": {
        "id": "sr9jDs2oO4wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calc_out_shape(input_matrix_shape, out_channels, kernel_size, stride, padding):\n",
        "    batch_size, channels_count, input_height, input_width = input_matrix_shape\n",
        "    output_height = (input_height + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n",
        "    output_width = (input_width + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n",
        "\n",
        "    return batch_size, out_channels, output_height, output_width"
      ],
      "metadata": {
        "id": "zqnOo4TjO5-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ABCConv2d(ABC):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def set_kernel(self, kernel):\n",
        "        self.kernel = kernel\n",
        "\n",
        "    @abstractmethod\n",
        "    def __call__(self, input_tensor):\n",
        "        pass"
      ],
      "metadata": {
        "id": "OLMXBCdRO71u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2d(ABCConv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
        "        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n",
        "                                      stride, padding=0, bias=False)\n",
        "\n",
        "    def set_kernel(self, kernel):\n",
        "        self.conv2d.weight.data = kernel\n",
        "\n",
        "    def __call__(self, input_tensor):\n",
        "        return self.conv2d(input_tensor)"
      ],
      "metadata": {
        "id": "TDhR-fgcO9lK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_and_call_conv2d_layer(conv2d_layer_class, stride, kernel, input_matrix):\n",
        "    out_channels = kernel.shape[0]\n",
        "    in_channels = kernel.shape[1]\n",
        "    kernel_size = kernel.shape[2]\n",
        "\n",
        "    layer = conv2d_layer_class(in_channels, out_channels, kernel_size, stride)\n",
        "    layer.set_kernel(kernel)\n",
        "\n",
        "    return layer(input_matrix)\n",
        "\n",
        "\n",
        "def test_conv2d_layer(conv2d_layer_class, batch_size=2,\n",
        "                      input_height=4, input_width=4, stride=2):\n",
        "    kernel = torch.tensor(\n",
        "                      [[[[0., 1, 0],\n",
        "                         [1,  2, 1],\n",
        "                         [0,  1, 0]],\n",
        "\n",
        "                        [[1, 2, 1],\n",
        "                         [0, 3, 3],\n",
        "                         [0, 1, 10]],\n",
        "\n",
        "                        [[10, 11, 12],\n",
        "                         [13, 14, 15],\n",
        "                         [16, 17, 18]]]])\n",
        "\n",
        "    in_channels = kernel.shape[1]\n",
        "\n",
        "    input_tensor = torch.arange(0, batch_size * in_channels *\n",
        "                                input_height * input_width,\n",
        "                                out=torch.FloatTensor()) \\\n",
        "        .reshape(batch_size, in_channels, input_height, input_width)\n",
        "\n",
        "    custom_conv2d_out = create_and_call_conv2d_layer(\n",
        "        conv2d_layer_class, stride, kernel, input_tensor)\n",
        "    conv2d_out = create_and_call_conv2d_layer(\n",
        "        Conv2d, stride, kernel, input_tensor)\n",
        "\n",
        "    print(conv2d_out)\n",
        "    return torch.allclose(custom_conv2d_out, conv2d_out) \\\n",
        "             and (custom_conv2d_out.shape == conv2d_out.shape)"
      ],
      "metadata": {
        "id": "-f8X0DtxPCCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "sMkSMfS-UUh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1wsUVThOnAx"
      },
      "outputs": [],
      "source": [
        "# Сверточный слой через циклы.\n",
        "class Conv2dLoop(ABCConv2d):\n",
        "    def __call__(self, input_tensor):\n",
        "        # input: (B, Cin, Hin, Win)\n",
        "        B, Cin, Hin, Win = input_tensor.shape\n",
        "        Cout = self.kernel.shape[0]\n",
        "        K = self.kernel.shape[2]\n",
        "        S = self.stride\n",
        "        P = 0  # в твоём задании padding=0\n",
        "\n",
        "        _, _, Hout, Wout = calc_out_shape(input_tensor.shape, Cout, K, S, P)\n",
        "        output = torch.zeros((B, Cout, Hout, Wout), dtype=input_tensor.dtype)\n",
        "\n",
        "        # PyTorch Conv2d = cross-correlation:\n",
        "        # out[b, oc, oy, ox] = sum_{ic, ky, kx} input[b, ic, oy*S+ky, ox*S+kx] * kernel[oc, ic, ky, kx]\n",
        "        for b in range(B):\n",
        "            for oc in range(Cout):\n",
        "                for oy in range(Hout):\n",
        "                    for ox in range(Wout):\n",
        "                        acc = 0.0\n",
        "                        iy0 = oy * S\n",
        "                        ix0 = ox * S\n",
        "                        for ic in range(Cin):\n",
        "                            for ky in range(K):\n",
        "                                for kx in range(K):\n",
        "                                    acc += (\n",
        "                                        input_tensor[b, ic, iy0 + ky, ix0 + kx]\n",
        "                                        * self.kernel[oc, ic, ky, kx]\n",
        "                                    )\n",
        "                        output[b, oc, oy, ox] = acc\n",
        "\n",
        "        return output\n",
        "\n",
        "# Корректность реализации определится в сравнении со стандартным слоем из pytorch.\n",
        "# Проверка происходит автоматически вызовом следующего кода\n",
        "# (раскомментируйте для самостоятельной проверки,\n",
        "#  в коде для сдачи задания должно быть закомментировано):"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_conv2d_layer(Conv2dLoop))"
      ],
      "metadata": {
        "id": "kGTgKc6wOrTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b9V47su9Y37p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "def calc_out_shape(input_matrix_shape, out_channels, kernel_size, stride, padding):\n",
        "    batch_size, channels_count, input_height, input_width = input_matrix_shape\n",
        "    output_height = (input_height + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n",
        "    output_width = (input_width + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n",
        "\n",
        "    return batch_size, out_channels, output_height, output_width\n",
        "\n",
        "\n",
        "class ABCConv2d(ABC):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def set_kernel(self, kernel):\n",
        "        self.kernel = kernel\n",
        "\n",
        "    @abstractmethod\n",
        "    def __call__(self, input_tensor):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Conv2d(ABCConv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
        "        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n",
        "                                      stride, padding=0, bias=False)\n",
        "\n",
        "    def set_kernel(self, kernel):\n",
        "        self.conv2d.weight.data = kernel\n",
        "\n",
        "    def __call__(self, input_tensor):\n",
        "        return self.conv2d(input_tensor)\n",
        "\n",
        "\n",
        "def create_and_call_conv2d_layer(conv2d_layer_class, stride, kernel, input_matrix):\n",
        "    out_channels = kernel.shape[0]\n",
        "    in_channels = kernel.shape[1]\n",
        "    kernel_size = kernel.shape[2]\n",
        "\n",
        "    layer = conv2d_layer_class(in_channels, out_channels, kernel_size, stride)\n",
        "    layer.set_kernel(kernel)\n",
        "\n",
        "    return layer(input_matrix)\n",
        "\n",
        "\n",
        "def test_conv2d_layer(conv2d_layer_class, batch_size=2,\n",
        "                      input_height=4, input_width=4, stride=2):\n",
        "    kernel = torch.tensor(\n",
        "                      [[[[0., 1, 0],\n",
        "                         [1,  2, 1],\n",
        "                         [0,  1, 0]],\n",
        "\n",
        "                        [[1, 2, 1],\n",
        "                         [0, 3, 3],\n",
        "                         [0, 1, 10]],\n",
        "\n",
        "                        [[10, 11, 12],\n",
        "                         [13, 14, 15],\n",
        "                         [16, 17, 18]]]])\n",
        "\n",
        "    in_channels = kernel.shape[1]\n",
        "\n",
        "    input_tensor = torch.arange(0, batch_size * in_channels *\n",
        "                                input_height * input_width,\n",
        "                                out=torch.FloatTensor()) \\\n",
        "        .reshape(batch_size, in_channels, input_height, input_width)\n",
        "\n",
        "    custom_conv2d_out = create_and_call_conv2d_layer(\n",
        "        conv2d_layer_class, stride, kernel, input_tensor)\n",
        "    conv2d_out = create_and_call_conv2d_layer(\n",
        "        Conv2d, stride, kernel, input_tensor)\n",
        "\n",
        "    return torch.allclose(custom_conv2d_out, conv2d_out) \\\n",
        "             and (custom_conv2d_out.shape == conv2d_out.shape)\n"
      ],
      "metadata": {
        "id": "4Q9nrl6FY4cy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2dMatrix(ABCConv2d):\n",
        "    # Функция преобразование кернела в матрицу нужного вида.\n",
        "    def _unsqueeze_kernel(self, torch_input, output_height, output_width):\n",
        "        # print(self.kernel, self.kernel.shape)\n",
        "        # print(torch_input, torch_input.shape)\n",
        "        In_shapes = torch_input.shape\n",
        "        K = self.kernel[0]\n",
        "        K_shapes = self.kernel.shape\n",
        "        kernel_unsqueezed = torch.tensor([[[0]*(In_shapes[-1]*In_shapes[-2])]*In_shapes[-2]]*K_shapes[1]).float() # Реализуйте функцию, возвращающую преобразованный кернел.\n",
        "        # print(kernel_unsqueezed)\n",
        "        # print(K_shapes)\n",
        "\n",
        "        for k in range(K_shapes[1]):\n",
        "            bias = 0\n",
        "            kernel = K[k]\n",
        "            # print(kernel)\n",
        "            string = []\n",
        "            for row in range(K_shapes[-1]):\n",
        "                string += list(kernel[row]) + [torch.tensor(0)]\n",
        "            string = torch.tensor(string)[:-1]\n",
        "            # print(string, len(string))\n",
        "\n",
        "            Un_shapes = kernel_unsqueezed.shape\n",
        "            # print(Un_shapes)\n",
        "            new = kernel_unsqueezed[k]\n",
        "            # print(new)\n",
        "            for row in range(Un_shapes[-2]):\n",
        "                new[row][bias:bias+len(string)] = string\n",
        "                if row%2==0: bias+=1\n",
        "                else: bias+=3\n",
        "            kernel_unsqueezed[k] = new\n",
        "            # print(kernel_unsqueezed)\n",
        "            # print(new, new.shape)\n",
        "\n",
        "\n",
        "\n",
        "            # print('\\n\\n\\n')\n",
        "        print(kernel_unsqueezed)\n",
        "        return kernel_unsqueezed\n",
        "\n",
        "    def __call__(self, torch_input):\n",
        "        batch_size, out_channels, output_height, output_width\\\n",
        "            = calc_out_shape(\n",
        "                input_matrix_shape=torch_input.shape,\n",
        "                out_channels=self.kernel.shape[0],\n",
        "                kernel_size=self.kernel.shape[2],\n",
        "                stride=self.stride,\n",
        "                padding=0)\n",
        "\n",
        "        kernel_unsqueezed = self._unsqueeze_kernel(torch_input, output_height, output_width)\n",
        "        result = kernel_unsqueezed @ torch_input.view((batch_size, -1)).permute(1, 0)\n",
        "        return result.permute(1, 0).view((batch_size, self.out_channels,\n",
        "                                          output_height, output_width))\n",
        "\n",
        "# Проверка происходит автоматически вызовом следующего кода\n",
        "# (раскомментируйте для самостоятельной проверки,\n",
        "#  в коде для сдачи задания должно быть закомментировано):\n",
        "# print(test_conv2d_layer(Conv2dMatrix))"
      ],
      "metadata": {
        "id": "7ieIXciuY8xH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2dMatrix(ABCConv2d):\n",
        "    def _unsqueeze_kernel(self, torch_input, output_height, output_width):\n",
        "        B, Cin, H, W = torch_input.shape\n",
        "        Cout, _, K, _ = self.kernel.shape\n",
        "        S = self.stride\n",
        "        print(B, Cin, H, W, '\\n', Cout, K,'\\n', S)\n",
        "\n",
        "        # W_big: (Cout*Hout*Wout, Cin*H*W)\n",
        "        W_big = torch.zeros((Cout * output_height * output_width, Cin * H * W),\n",
        "                            dtype=torch_input.dtype)\n",
        "        print(W_big, W_big.shape)\n",
        "\n",
        "        row = 0\n",
        "        for oc in range(Cout):\n",
        "            for oy in range(output_height):\n",
        "                for ox in range(output_width):\n",
        "                    print(ox, oy)\n",
        "                    iy0 = oy * S\n",
        "                    ix0 = ox * S\n",
        "                    for ic in range(Cin):\n",
        "                        for ky in range(K):\n",
        "                            for kx in range(K):\n",
        "                                iy = iy0 + ky\n",
        "                                ix = ix0 + kx\n",
        "                                col = ic * (H * W) + iy * W + ix\n",
        "                                W_big[row, col] = self.kernel[oc, ic, ky, kx]\n",
        "                    row += 1\n",
        "        print(W_big, W_big.shape)\n",
        "        return W_big\n",
        "\n",
        "    def __call__(self, torch_input):\n",
        "        batch_size, out_channels, output_height, output_width\\\n",
        "            = calc_out_shape(\n",
        "                input_matrix_shape=torch_input.shape,\n",
        "                out_channels=self.kernel.shape[0],\n",
        "                kernel_size=self.kernel.shape[2],\n",
        "                stride=self.stride,\n",
        "                padding=0)\n",
        "\n",
        "        kernel_unsqueezed = self._unsqueeze_kernel(torch_input, output_height, output_width)\n",
        "        result = kernel_unsqueezed @ torch_input.view((batch_size, -1)).permute(1, 0)\n",
        "        return result.permute(1, 0).view((batch_size, self.out_channels,\n",
        "                                          output_height, output_width))"
      ],
      "metadata": {
        "id": "Zjc_rLQXi56o"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_conv2d_layer(Conv2dMatrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqF6DO88ZDuZ",
        "outputId": "4e2b6249-bbe5-4005-bfa9-cd5e0b6e540e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 3 4 4 \n",
            " 1 3 \n",
            " 2\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]) torch.Size([1, 48])\n",
            "0 0\n",
            "tensor([[ 0.,  1.,  0.,  0.,  1.,  2.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
            "          0.,  0.,  1.,  2.,  1.,  0.,  0.,  3.,  3.,  0.,  0.,  1., 10.,  0.,\n",
            "          0.,  0.,  0.,  0., 10., 11., 12.,  0., 13., 14., 15.,  0., 16., 17.,\n",
            "         18.,  0.,  0.,  0.,  0.,  0.]]) torch.Size([1, 48])\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_zk6pg_M-8Kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from abc import ABC, abstractmethod\n",
        "\n",
        "\n",
        "def calc_out_shape(input_matrix_shape, out_channels, kernel_size, stride, padding):\n",
        "    batch_size, channels_count, input_height, input_width = input_matrix_shape\n",
        "    output_height = (input_height + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n",
        "    output_width = (input_width + 2 * padding - (kernel_size - 1) - 1) // stride + 1\n",
        "\n",
        "    return batch_size, out_channels, output_height, output_width\n",
        "\n",
        "\n",
        "class ABCConv2d(ABC):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "\n",
        "    def set_kernel(self, kernel):\n",
        "        self.kernel = kernel\n",
        "\n",
        "    @abstractmethod\n",
        "    def __call__(self, input_tensor):\n",
        "        pass\n",
        "\n",
        "\n",
        "def create_and_call_conv2d_layer(conv2d_layer_class, stride, kernel, input_matrix):\n",
        "    out_channels = kernel.shape[0]\n",
        "    in_channels = kernel.shape[1]\n",
        "    kernel_size = kernel.shape[2]\n",
        "\n",
        "    layer = conv2d_layer_class(in_channels, out_channels, kernel_size, stride)\n",
        "    layer.set_kernel(kernel)\n",
        "\n",
        "    return layer(input_matrix)\n",
        "\n",
        "\n",
        "class Conv2d(ABCConv2d):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride):\n",
        "        self.conv2d = torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n",
        "                                      stride, padding=0, bias=False)\n",
        "\n",
        "    def set_kernel(self, kernel):\n",
        "        self.conv2d.weight.data = kernel\n",
        "\n",
        "    def __call__(self, input_tensor):\n",
        "        return self.conv2d(input_tensor)\n",
        "\n",
        "\n",
        "def test_conv2d_layer(conv2d_layer_class, batch_size=2,\n",
        "                      input_height=4, input_width=4, stride=2):\n",
        "    kernel = torch.tensor(\n",
        "                      [[[[0., 1, 0],\n",
        "                         [1,  2, 1],\n",
        "                         [0,  1, 0]],\n",
        "\n",
        "                        [[1, 2, 1],\n",
        "                         [0, 3, 3],\n",
        "                         [0, 1, 10]],\n",
        "\n",
        "                        [[10, 11, 12],\n",
        "                         [13, 14, 15],\n",
        "                         [16, 17, 18]]]])\n",
        "\n",
        "    in_channels = kernel.shape[1]\n",
        "\n",
        "    input_tensor = torch.arange(0, batch_size * in_channels *\n",
        "                                input_height * input_width,\n",
        "                                out=torch.FloatTensor()) \\\n",
        "        .reshape(batch_size, in_channels, input_height, input_width)\n",
        "\n",
        "    custom_conv2d_out = create_and_call_conv2d_layer(\n",
        "        conv2d_layer_class, stride, kernel, input_tensor)\n",
        "    conv2d_out = create_and_call_conv2d_layer(\n",
        "        Conv2d, stride, kernel, input_tensor)\n",
        "\n",
        "    return torch.allclose(custom_conv2d_out, conv2d_out) \\\n",
        "             and (custom_conv2d_out.shape == conv2d_out.shape)\n"
      ],
      "metadata": {
        "id": "3AZs_Fjb-8uO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2dMatrixV2(ABCConv2d):\n",
        "    # Функция преобразования кернела в нужный формат.\n",
        "    def _convert_kernel(self):\n",
        "        B, N, H, W = self.kernel.shape\n",
        "\n",
        "        converted_kernel = torch.zeros((B, N*H*W))  # Реализуйте преобразование кернела.\n",
        "        S_reshape = H*W\n",
        "        for b in range(B):\n",
        "            for k in range(N):\n",
        "                converted_kernel[b][k*S_reshape:k*S_reshape+S_reshape] = self.kernel[b][k].reshape((1,S_reshape))\n",
        "\n",
        "        return converted_kernel\n",
        "\n",
        "    # Функция преобразования входа в нужный формат.\n",
        "    def _convert_input(self, torch_input, output_height, output_width):\n",
        "        B, N, H, W = torch_input.shape\n",
        "        _, _, Kh, Kw = self.kernel.shape\n",
        "\n",
        "        calc_out_size = lambda s: (s-self.kernel_size)//self.stride + 1\n",
        "\n",
        "        H_out, W_out = calc_out_size(H), calc_out_size(W)\n",
        "\n",
        "        converted_input = torch.zeros((N*Kh*Kw, B*H_out*W_out)) # Реализуйте преобразование входа.\n",
        "\n",
        "        col = 0\n",
        "        for b in range(B):\n",
        "            for oy in range(output_height):\n",
        "                for ox in range(output_width):\n",
        "                    ix = ox * self.stride\n",
        "                    iy = oy * self.stride\n",
        "                    row = 0\n",
        "                    for c in range(N):\n",
        "                        patch = torch_input[b, c, iy:iy+Kh, ix:ix+Kw].reshape(-1)   # (Kh*Kw,)\n",
        "                        converted_input[row:row + Kh*Kw, col] = patch\n",
        "                        row += Kh * Kw\n",
        "\n",
        "                    col += 1\n",
        "\n",
        "        return converted_input\n",
        "\n",
        "    def __call__(self, torch_input):\n",
        "        batch_size, out_channels, output_height, output_width\\\n",
        "            = calc_out_shape(\n",
        "                input_matrix_shape=torch_input.shape,\n",
        "                out_channels=self.kernel.shape[0],\n",
        "                kernel_size=self.kernel.shape[2],\n",
        "                stride=self.stride,\n",
        "                padding=0)\n",
        "\n",
        "        converted_kernel = self._convert_kernel()\n",
        "        converted_input = self._convert_input(torch_input, output_height, output_width)\n",
        "\n",
        "        conv2d_out_alternative_matrix_v2 = converted_kernel @ converted_input\n",
        "        return conv2d_out_alternative_matrix_v2.transpose(1,0).view(torch_input.shape[0],\n",
        "                                                     self.out_channels,\n",
        "                                                     output_height,\n",
        "                                                     output_width)\n",
        "\n",
        "# Проверка происходит автоматически вызовом следующего кода\n",
        "# (раскомментируйте для самостоятельной проверки,\n",
        "#  в коде для сдачи задания должно быть закомментировано):\n",
        "# print(test_conv2d_layer(Conv2dMatrixV2))"
      ],
      "metadata": {
        "id": "jVNy0VN3-_ww"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_conv2d_layer(Conv2dMatrixV2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dqlTBRF_BoU",
        "outputId": "98994d30-b663-416e-ad5b-f4499b725ad1"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.,  1.,  2.,  3.],\n",
            "          [ 4.,  5.,  6.,  7.],\n",
            "          [ 8.,  9., 10., 11.],\n",
            "          [12., 13., 14., 15.]],\n",
            "\n",
            "         [[16., 17., 18., 19.],\n",
            "          [20., 21., 22., 23.],\n",
            "          [24., 25., 26., 27.],\n",
            "          [28., 29., 30., 31.]],\n",
            "\n",
            "         [[32., 33., 34., 35.],\n",
            "          [36., 37., 38., 39.],\n",
            "          [40., 41., 42., 43.],\n",
            "          [44., 45., 46., 47.]]],\n",
            "\n",
            "\n",
            "        [[[48., 49., 50., 51.],\n",
            "          [52., 53., 54., 55.],\n",
            "          [56., 57., 58., 59.],\n",
            "          [60., 61., 62., 63.]],\n",
            "\n",
            "         [[64., 65., 66., 67.],\n",
            "          [68., 69., 70., 71.],\n",
            "          [72., 73., 74., 75.],\n",
            "          [76., 77., 78., 79.]],\n",
            "\n",
            "         [[80., 81., 82., 83.],\n",
            "          [84., 85., 86., 87.],\n",
            "          [88., 89., 90., 91.],\n",
            "          [92., 93., 94., 95.]]]]) torch.Size([2, 3, 4, 4])\n",
            "tensor([ 0.,  1.,  2.,  4.,  5.,  6.,  8.,  9., 10.])\n",
            "tensor([16., 17., 18., 20., 21., 22., 24., 25., 26.])\n",
            "tensor([32., 33., 34., 36., 37., 38., 40., 41., 42.])\n",
            "tensor([48., 49., 50., 52., 53., 54., 56., 57., 58.])\n",
            "tensor([64., 65., 66., 68., 69., 70., 72., 73., 74.])\n",
            "tensor([80., 81., 82., 84., 85., 86., 88., 89., 90.])\n",
            "tensor([[ 0., 48.],\n",
            "        [ 1., 49.],\n",
            "        [ 2., 50.],\n",
            "        [ 4., 52.],\n",
            "        [ 5., 53.],\n",
            "        [ 6., 54.],\n",
            "        [ 8., 56.],\n",
            "        [ 9., 57.],\n",
            "        [10., 58.],\n",
            "        [16., 64.],\n",
            "        [17., 65.],\n",
            "        [18., 66.],\n",
            "        [20., 68.],\n",
            "        [21., 69.],\n",
            "        [22., 70.],\n",
            "        [24., 72.],\n",
            "        [25., 73.],\n",
            "        [26., 74.],\n",
            "        [32., 80.],\n",
            "        [33., 81.],\n",
            "        [34., 82.],\n",
            "        [36., 84.],\n",
            "        [37., 85.],\n",
            "        [38., 86.],\n",
            "        [40., 88.],\n",
            "        [41., 89.],\n",
            "        [42., 90.]])\n",
            "True\n"
          ]
        }
      ]
    }
  ]
}